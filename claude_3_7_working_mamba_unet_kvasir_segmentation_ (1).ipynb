{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CIoXdxM3LxT",
        "outputId": "2afefc5b-76b6-44e0-de72-f3f191ef602c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install gdown tqdm matplotlib pillow einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "from einops import rearrange, repeat\n",
        "import math\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "import glob\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Download and Setup - No changes needed\n",
        "# -------------------------\n",
        "def download_and_setup_dataset(force_download=False):\n",
        "    \"\"\"Download and properly set up Kvasir-SEG dataset\"\"\"\n",
        "    base_path = './datasets'\n",
        "    kvasir_path = os.path.join(base_path, 'kvasir-seg')\n",
        "\n",
        "    # Make sure base directory exists\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Check if dataset already exists in the expected directory structure\n",
        "    if os.path.exists(os.path.join(kvasir_path, 'images')) and \\\n",
        "       os.path.exists(os.path.join(kvasir_path, 'masks')) and \\\n",
        "       len(os.listdir(os.path.join(kvasir_path, 'images'))) > 0 and \\\n",
        "       not force_download:\n",
        "        print(\"Kvasir-SEG dataset already exists.\")\n",
        "        return kvasir_path\n",
        "\n",
        "    # Direct URL to the zip file\n",
        "    dataset_url = \"https://datasets.simula.no/downloads/kvasir-seg.zip\"\n",
        "    zip_path = os.path.join(base_path, 'kvasir-seg.zip')\n",
        "\n",
        "    # Download the dataset\n",
        "    print(\"Downloading Kvasir-SEG dataset...\")\n",
        "    try:\n",
        "        response = requests.get(dataset_url, stream=True)\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        block_size = 1024\n",
        "        progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            for data in response.iter_content(block_size):\n",
        "                progress_bar.update(len(data))\n",
        "                f.write(data)\n",
        "        progress_bar.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Download completed, file saved to {zip_path}\")\n",
        "\n",
        "    # Extract the dataset\n",
        "    print(\"Extracting dataset...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(base_path)\n",
        "        print(\"Extraction completed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Check the structure of extracted files\n",
        "    extracted_files = glob.glob(os.path.join(base_path, \"**\"), recursive=True)\n",
        "    print(\"Extracted file structure:\")\n",
        "    for file in extracted_files[:10]:  # Show only first 10 files\n",
        "        print(f\"  {file}\")\n",
        "    if len(extracted_files) > 10:\n",
        "        print(f\"  ... and {len(extracted_files)-10} more files\")\n",
        "\n",
        "    # Locate the images and masks directories\n",
        "    image_dirs = glob.glob(os.path.join(base_path, \"**/images\"), recursive=True)\n",
        "    mask_dirs = glob.glob(os.path.join(base_path, \"**/masks\"), recursive=True)\n",
        "\n",
        "    print(f\"Found image directories: {image_dirs}\")\n",
        "    print(f\"Found mask directories: {mask_dirs}\")\n",
        "\n",
        "    # Ensure proper directory structure\n",
        "    os.makedirs(os.path.join(kvasir_path, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(kvasir_path, 'masks'), exist_ok=True)\n",
        "\n",
        "    # Copy files to the expected location if needed\n",
        "    if image_dirs and mask_dirs:\n",
        "        src_image_dir = image_dirs[0]\n",
        "        src_mask_dir = mask_dirs[0]\n",
        "\n",
        "        if src_image_dir != os.path.join(kvasir_path, 'images'):\n",
        "            print(f\"Moving images from {src_image_dir} to {os.path.join(kvasir_path, 'images')}\")\n",
        "            for img_file in os.listdir(src_image_dir):\n",
        "                shutil.copy(\n",
        "                    os.path.join(src_image_dir, img_file),\n",
        "                    os.path.join(kvasir_path, 'images', img_file)\n",
        "                )\n",
        "\n",
        "        if src_mask_dir != os.path.join(kvasir_path, 'masks'):\n",
        "            print(f\"Moving masks from {src_mask_dir} to {os.path.join(kvasir_path, 'masks')}\")\n",
        "            for mask_file in os.listdir(src_mask_dir):\n",
        "                shutil.copy(\n",
        "                    os.path.join(src_mask_dir, mask_file),\n",
        "                    os.path.join(kvasir_path, 'masks', mask_file)\n",
        "                )\n",
        "\n",
        "    # Clean up\n",
        "    try:\n",
        "        os.remove(zip_path)\n",
        "        print(\"Removed zip file.\")\n",
        "    except:\n",
        "        print(\"Could not remove zip file.\")\n",
        "\n",
        "    # Verify the dataset is now properly set up\n",
        "    if os.path.exists(os.path.join(kvasir_path, 'images')) and \\\n",
        "       os.path.exists(os.path.join(kvasir_path, 'masks')) and \\\n",
        "       len(os.listdir(os.path.join(kvasir_path, 'images'))) > 0:\n",
        "        print(\"Dataset setup completed successfully.\")\n",
        "        print(f\"Found {len(os.listdir(os.path.join(kvasir_path, 'images')))} images and \"\n",
        "              f\"{len(os.listdir(os.path.join(kvasir_path, 'masks')))} masks.\")\n",
        "        return kvasir_path\n",
        "    else:\n",
        "        print(\"Dataset setup failed.\")\n",
        "        return None\n",
        "\n",
        "# -------------------------\n",
        "# Dataset class with augmentation\n",
        "# -------------------------\n",
        "class KvasirSEGDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None, target_transform=None, augment=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.augment = augment and split == 'train'  # Only augment training data\n",
        "        self.img_dir = os.path.join(root_dir, 'images')\n",
        "        self.mask_dir = os.path.join(root_dir, 'masks')\n",
        "\n",
        "        # Verify directories exist\n",
        "        if not os.path.exists(self.img_dir):\n",
        "            raise ValueError(f\"Images directory not found: {self.img_dir}\")\n",
        "        if not os.path.exists(self.mask_dir):\n",
        "            raise ValueError(f\"Masks directory not found: {self.mask_dir}\")\n",
        "\n",
        "        # Get all image files\n",
        "        self.images = sorted([f for f in os.listdir(self.img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        if not self.images:\n",
        "            raise ValueError(f\"No images found in {self.img_dir}\")\n",
        "\n",
        "        # Print some sample image names for debugging\n",
        "        print(f\"Sample image names: {self.images[:5]}\")\n",
        "\n",
        "        # Split data into train/val/test (80/10/10 split)\n",
        "        np.random.seed(42)  # For reproducibility\n",
        "        indices = np.random.permutation(len(self.images))\n",
        "\n",
        "        if split == 'train':\n",
        "            self.images = [self.images[i] for i in indices[:int(0.8 * len(self.images))]]\n",
        "        elif split == 'val':\n",
        "            self.images = [self.images[i] for i in indices[int(0.8 * len(self.images)):int(0.9 * len(self.images))]]\n",
        "        else:  # test\n",
        "            self.images = [self.images[i] for i in indices[int(0.9 * len(self.images)):]]\n",
        "\n",
        "        print(f\"Created {split} dataset with {len(self.images)} images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        # Find corresponding mask\n",
        "        base_name = os.path.splitext(img_name)[0]\n",
        "        mask_candidates = [\n",
        "            os.path.join(self.mask_dir, base_name + ext)\n",
        "            for ext in ['.jpg', '.png', '.jpeg', '.tif']\n",
        "        ]\n",
        "        mask_path = next((path for path in mask_candidates if os.path.exists(path)), None)\n",
        "\n",
        "        if not mask_path:\n",
        "            # Look for files that start with the same name\n",
        "            mask_files = os.listdir(self.mask_dir)\n",
        "            matches = [f for f in mask_files if f.startswith(base_name)]\n",
        "            if matches:\n",
        "                mask_path = os.path.join(self.mask_dir, matches[0])\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"No mask found for image {img_name}\")\n",
        "\n",
        "        # Print paths for debugging (only for the first item)\n",
        "        if idx == 0:\n",
        "            print(f\"Image path: {img_path}\")\n",
        "            print(f\"Mask path: {mask_path}\")\n",
        "\n",
        "        # Load image and mask\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        # Apply augmentation if enabled\n",
        "        if self.augment:\n",
        "            # Random horizontal flip\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.hflip(image)\n",
        "                mask = TF.hflip(mask)\n",
        "\n",
        "            # Random vertical flip\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.vflip(image)\n",
        "                mask = TF.vflip(mask)\n",
        "\n",
        "            # Random rotation\n",
        "            if random.random() > 0.5:\n",
        "                angle = random.choice([90, 180, 270])\n",
        "                fill = 0\n",
        "                image = TF.rotate(image, angle, fill=fill)\n",
        "                mask = TF.rotate(mask, angle, fill=fill)\n",
        "\n",
        "            # Color jitter (only for image)\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.adjust_brightness(image, random.uniform(0.8, 1.2))\n",
        "                image = TF.adjust_contrast(image, random.uniform(0.8, 1.2))\n",
        "                image = TF.adjust_saturation(image, random.uniform(0.8, 1.2))\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "        else:\n",
        "            # Default transformation for masks\n",
        "            mask_array = np.array(mask)\n",
        "            mask_binary = (mask_array > 0).astype(np.int64)\n",
        "            mask = torch.from_numpy(mask_binary).long()  # Explicit cast to long\n",
        "\n",
        "        # For debugging: print data types and ranges (only for the first item)\n",
        "        if idx == 0:\n",
        "            print(f\"Image shape: {image.shape}, dtype: {image.dtype}, range: [{image.min()}, {image.max()}]\")\n",
        "            print(f\"Mask shape: {mask.shape}, dtype: {mask.dtype}, range: [{mask.min()}, {mask.max()}]\")\n",
        "\n",
        "        # Ensure mask is 2D (H,W) not 3D (1,H,W)\n",
        "        if mask.dim() == 3 and mask.size(0) == 1:\n",
        "            mask = mask.squeeze(0)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# -------------------------\n",
        "# Enhanced Selective Scan with Numerical Stability\n",
        "# -------------------------\n",
        "def selective_scan(u, delta, A, B, C, D):\n",
        "    # Add numerical stability measures\n",
        "    # Clamp A values to prevent extreme values\n",
        "    A = torch.clamp(A, min=-5.0, max=5.0)\n",
        "\n",
        "    dA = torch.einsum('bld,dn->bldn', delta, A)\n",
        "    dB_u = torch.einsum('bld,bld,bln->bldn', delta, u, B)\n",
        "\n",
        "    dA_cumsum = torch.cat([dA[:, 1:], torch.zeros_like(dA[:, :1])], dim=1)\n",
        "    dA_cumsum = torch.flip(dA_cumsum, dims=[1])\n",
        "    dA_cumsum = torch.cumsum(dA_cumsum, dim=1)\n",
        "    # Prevent overflow in exponential\n",
        "    dA_cumsum = torch.clamp(dA_cumsum, max=15.0)\n",
        "    dA_cumsum = torch.exp(dA_cumsum)\n",
        "    dA_cumsum = torch.flip(dA_cumsum, dims=[1])\n",
        "\n",
        "    x = dB_u * dA_cumsum\n",
        "    x = torch.cumsum(x, dim=1) / (dA_cumsum + 1e-6)\n",
        "\n",
        "    y = torch.einsum('bldn,bln->bld', x, C)\n",
        "    return y + u * D\n",
        "\n",
        "# -------------------------\n",
        "# Combined Loss Function\n",
        "# -------------------------\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.dice_weight = dice_weight\n",
        "        self.bce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # BCE Loss\n",
        "        bce = self.bce_loss(inputs, targets)\n",
        "\n",
        "        # Dice Loss\n",
        "        inputs_soft = F.softmax(inputs, dim=1)\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n",
        "\n",
        "        # Calculate Dice loss manually\n",
        "        intersection = (inputs_soft * targets_one_hot).sum(dim=(2, 3))\n",
        "        cardinality = inputs_soft.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))\n",
        "\n",
        "        dice = (2. * intersection / (cardinality + 1e-6)).mean()\n",
        "        dice_loss = 1 - dice\n",
        "\n",
        "        # Combined loss\n",
        "        return self.bce_weight * bce + self.dice_weight * dice_loss\n",
        "\n",
        "# -------------------------\n",
        "# Improved MambaBlock with Gradient Checkpointing\n",
        "# -------------------------\n",
        "class MambaBlock(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.in_proj = nn.Linear(args.model_input_dims, args.model_internal_dim * 2, bias=False)\n",
        "        self.conv1d = nn.Conv1d(args.model_internal_dim, args.model_internal_dim, kernel_size=args.conv_kernel_size,\n",
        "                               padding=args.conv_kernel_size-1, groups=args.model_internal_dim)\n",
        "        self.x_proj = nn.Linear(args.model_internal_dim, args.delta_t_rank + args.model_states * 2, bias=False)\n",
        "        self.delta_proj = nn.Linear(args.delta_t_rank, args.model_internal_dim)\n",
        "\n",
        "        # Initialize A values more carefully for better gradient flow\n",
        "        A_vals = torch.arange(1, args.model_states + 1).float() / args.model_states * 3\n",
        "        self.A_log = nn.Parameter(torch.log(repeat(A_vals, 'n -> d n', d=args.model_internal_dim)))\n",
        "        self.D = nn.Parameter(torch.ones(args.model_internal_dim))\n",
        "        self.out_proj = nn.Linear(args.model_internal_dim, args.model_input_dims, bias=args.dense_use_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use gradient checkpointing for better memory efficiency during training\n",
        "        if self.training:\n",
        "            return torch.utils.checkpoint.checkpoint(self._forward, x, use_reentrant=False)\n",
        "        else:\n",
        "            return self._forward(x)\n",
        "\n",
        "    def _forward(self, x):\n",
        "        b, l, d = x.shape\n",
        "        x_and_res = self.in_proj(x)\n",
        "        x1, res = x_and_res.chunk(2, dim=-1)\n",
        "\n",
        "        x1 = rearrange(x1, 'b l d -> b d l')\n",
        "        x1 = self.conv1d(x1)[..., :l]\n",
        "        x1 = rearrange(x1, 'b d l -> b l d')\n",
        "        x1 = F.silu(x1)\n",
        "\n",
        "        # Apply bounded values for more stability\n",
        "        A = -torch.exp(torch.clamp(self.A_log, min=-5, max=5))\n",
        "        D = self.D\n",
        "        x_dbl = self.x_proj(x1)\n",
        "        delta, B, C = torch.split(x_dbl, [self.args.delta_t_rank, self.args.model_states, self.args.model_states], dim=-1)\n",
        "        delta = F.softplus(self.delta_proj(delta))\n",
        "\n",
        "        y = selective_scan(x1, delta, A, B, C, D)\n",
        "        y = y * F.silu(res)\n",
        "        return self.out_proj(y)\n",
        "\n",
        "# -------------------------\n",
        "# Enhanced Residual Block with Dropout and Layer Norm\n",
        "# -------------------------\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(args.model_input_dims)\n",
        "        self.mixer = MambaBlock(args)\n",
        "        self.dropout = nn.Dropout(args.dropout_rate)\n",
        "        self.norm2 = nn.LayerNorm(args.model_input_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # More transformer-like architecture with normalization\n",
        "        residual = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.mixer(x)\n",
        "        x = self.dropout(x)\n",
        "        x = residual + x\n",
        "        return self.norm2(x)\n",
        "\n",
        "# -------------------------\n",
        "# Enhanced Double Convolution with BN and Residual Connection (No CBAM)\n",
        "# -------------------------\n",
        "class DoubleConvWithResidual(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.same_channels = in_channels == out_channels\n",
        "\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Optional projection for residual connection when channel sizes differ\n",
        "        if not self.same_channels:\n",
        "            self.project = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x if self.same_channels else self.project(x)\n",
        "        x = self.double_conv(x)\n",
        "        x = x + identity  # Residual connection\n",
        "        return x\n",
        "\n",
        "# -------------------------\n",
        "# Improved Model Args for Better Performance\n",
        "# -------------------------\n",
        "class ModelArgs:\n",
        "    def __init__(self):\n",
        "        # Model dimensions\n",
        "        self.model_input_dims = 96\n",
        "        self.model_states = 96\n",
        "        self.projection_expand_factor = 2\n",
        "        self.conv_kernel_size = 4\n",
        "        self.conv_use_bias = False\n",
        "        self.dense_use_bias = False\n",
        "        self.layer_id = -1\n",
        "        self.seq_length = 256\n",
        "        self.num_layers = 4\n",
        "        self.dropout_rate = 0.2\n",
        "        self.use_lm_head = False\n",
        "        self.num_classes = 2  # Binary segmentation\n",
        "        self.final_activation = 'none'\n",
        "        self.model_internal_dim = self.projection_expand_factor * self.model_input_dims\n",
        "        self.delta_t_rank = math.ceil(self.model_input_dims / 16)\n",
        "\n",
        "# -------------------------\n",
        "# Fixed Mamba-UNet Architecture with Deep Supervision (No CBAM)\n",
        "# -------------------------\n",
        "class MambaUNetSegmentationEnhanced(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder path with more channels\n",
        "        self.encoder1 = DoubleConvWithResidual(3, 64)  # Input: 3 RGB channels\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.encoder2 = DoubleConvWithResidual(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.encoder3 = DoubleConvWithResidual(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Mamba blocks in the bottleneck\n",
        "        self.mamba_blocks = nn.Sequential(*[ResidualBlock(args) for _ in range(args.num_layers)])\n",
        "\n",
        "        # Bridge between CNN and Mamba: Projection to adjust dimensions\n",
        "        self.bridge_down = nn.Conv2d(256, args.model_input_dims, kernel_size=1)\n",
        "        self.bridge_up = nn.Conv2d(args.model_input_dims, 256, kernel_size=1)\n",
        "\n",
        "        # Decoder path with skip connections and deep supervision\n",
        "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.decoder3 = DoubleConvWithResidual(256, 128)  # 256 = 128 + 128 (skip)\n",
        "        self.deep_sup3 = nn.Conv2d(128, args.num_classes, kernel_size=1)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.decoder2 = DoubleConvWithResidual(128, 64)  # 128 = 64 + 64 (skip)\n",
        "        self.deep_sup2 = nn.Conv2d(64, args.num_classes, kernel_size=1)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        # FIXED: Correct the channel dimension to match the concatenated input\n",
        "        self.decoder1 = DoubleConvWithResidual(32 + 3, 32)  # 32+3 = 32 (from upconv1) + 3 (original input)\n",
        "\n",
        "        # Final layer\n",
        "        self.final_conv = nn.Conv2d(32, args.num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, return_deep=False):\n",
        "        # Encoder path\n",
        "        enc1 = self.encoder1(x)      # 64 channels\n",
        "        enc1_pool = self.pool1(enc1)\n",
        "\n",
        "        enc2 = self.encoder2(enc1_pool)  # 128 channels\n",
        "        enc2_pool = self.pool2(enc2)\n",
        "\n",
        "        enc3 = self.encoder3(enc2_pool)  # 256 channels\n",
        "        enc3_pool = self.pool3(enc3)\n",
        "\n",
        "        # Bridge to Mamba\n",
        "        bridge_out = self.bridge_down(enc3_pool)\n",
        "\n",
        "        # Reshape for Mamba blocks\n",
        "        b, c, h, w = bridge_out.size()\n",
        "        mamba_input = bridge_out.permute(0, 2, 3, 1).reshape(b, h * w, c)\n",
        "\n",
        "        # Apply Mamba blocks\n",
        "        mamba_output = self.mamba_blocks(mamba_input)\n",
        "\n",
        "        # Reshape back to 2D\n",
        "        mamba_output = mamba_output.reshape(b, h, w, c).permute(0, 3, 1, 2)\n",
        "\n",
        "        # Bridge back to CNN\n",
        "        mamba_output = self.bridge_up(mamba_output)\n",
        "\n",
        "        # Decoder path with skip connections\n",
        "        dec3 = self.upconv3(mamba_output)\n",
        "        # Ensure dimensions match\n",
        "        if dec3.shape[2:] != enc2.shape[2:]:\n",
        "            dec3 = F.interpolate(dec3, size=enc2.shape[2:], mode='bilinear', align_corners=True)\n",
        "        dec3 = torch.cat([dec3, enc2], dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        deep_out3 = self.deep_sup3(dec3)\n",
        "\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        if dec2.shape[2:] != enc1.shape[2:]:\n",
        "            dec2 = F.interpolate(dec2, size=enc1.shape[2:], mode='bilinear', align_corners=True)\n",
        "        dec2 = torch.cat([dec2, enc1], dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        deep_out2 = self.deep_sup2(dec2)\n",
        "\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        # Interpolate to match original input size and add skip connection to input\n",
        "        if dec1.shape[2:] != x.shape[2:]:\n",
        "            dec1 = F.interpolate(dec1, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
        "        dec1 = torch.cat([dec1, x], dim=1)  # Skip connection to original input\n",
        "        dec1 = self.decoder1(dec1)\n",
        "\n",
        "        # Final layer\n",
        "        out = self.final_conv(dec1)\n",
        "\n",
        "        if return_deep:\n",
        "            # Return main output and deep supervision outputs\n",
        "            deep_out2 = F.interpolate(deep_out2, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
        "            deep_out3 = F.interpolate(deep_out3, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
        "            return out, deep_out2, deep_out3\n",
        "\n",
        "        return out\n",
        "\n",
        "# -------------------------\n",
        "# Deep Supervision Loss\n",
        "# -------------------------\n",
        "class DeepSupervisionLoss(nn.Module):\n",
        "    def __init__(self, main_weight=0.6, deep2_weight=0.2, deep3_weight=0.2):\n",
        "        super(DeepSupervisionLoss, self).__init__()\n",
        "        self.main_weight = main_weight\n",
        "        self.deep2_weight = deep2_weight\n",
        "        self.deep3_weight = deep3_weight\n",
        "        self.criterion = CombinedLoss(bce_weight=0.5, dice_weight=0.5)\n",
        "\n",
        "    def forward(self, outputs, target):\n",
        "        main_out, deep2, deep3 = outputs\n",
        "\n",
        "        loss_main = self.criterion(main_out, target)\n",
        "        loss_deep2 = self.criterion(deep2, target)\n",
        "        loss_deep3 = self.criterion(deep3, target)\n",
        "\n",
        "        total_loss = (\n",
        "            self.main_weight * loss_main +\n",
        "            self.deep2_weight * loss_deep2 +\n",
        "            self.deep3_weight * loss_deep3\n",
        "        )\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation Metrics\n",
        "# -------------------------\n",
        "def calculate_iou(pred_mask, gt_mask):\n",
        "    \"\"\"Calculate IoU for binary segmentation\"\"\"\n",
        "    pred_mask = (pred_mask > 0).cpu().numpy().astype(bool)\n",
        "    gt_mask = (gt_mask > 0).cpu().numpy().astype(bool)\n",
        "\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
        "\n",
        "    if union == 0:\n",
        "        return 1.0  # If both masks are empty, IoU is 1\n",
        "\n",
        "    return intersection / union\n",
        "\n",
        "def calculate_dice(pred_mask, gt_mask):\n",
        "    \"\"\"Calculate Dice coefficient\"\"\"\n",
        "    pred_mask = (pred_mask > 0).cpu().numpy().astype(bool)\n",
        "    gt_mask = (gt_mask > 0).cpu().numpy().astype(bool)\n",
        "\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    sum_areas = pred_mask.sum() + gt_mask.sum()\n",
        "\n",
        "    if sum_areas == 0:\n",
        "        return 1.0  # If both masks are empty, Dice is 1\n",
        "\n",
        "    return 2.0 * intersection / sum_areas\n",
        "\n",
        "# -------------------------\n",
        "# Enhanced Training Function\n",
        "# -------------------------\n",
        "def train_one_epoch_enhanced(model, dataloader, optimizer, criterion, device, scheduler=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_iou = 0.0\n",
        "    running_dice = 0.0\n",
        "    sample_count = 0\n",
        "\n",
        "    pbar = tqdm(dataloader, desc='Training')\n",
        "\n",
        "    for i, (images, masks) in enumerate(pbar):\n",
        "        # Move data to device\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        # Check data shape for the first batch\n",
        "        if i == 0:\n",
        "            print(f\"Training batch - Images: {images.shape}, Masks: {masks.shape}\")\n",
        "            print(f\"Masks unique values: {torch.unique(masks)}\")\n",
        "\n",
        "        # Forward pass with deep supervision\n",
        "        outputs = model(images, return_deep=True)\n",
        "\n",
        "        # Calculate loss with deep supervision\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # Optional gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Step scheduler if provided\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Get main output for metrics calculation\n",
        "        main_output = outputs[0]\n",
        "\n",
        "        # Calculate metrics\n",
        "        batch_size = images.size(0)\n",
        "        preds = torch.argmax(main_output, dim=1)\n",
        "\n",
        "        # Update statistics\n",
        "        running_loss += loss.item() * batch_size\n",
        "\n",
        "        # Calculate metrics per image\n",
        "        batch_iou = 0\n",
        "        batch_dice = 0\n",
        "        for j in range(batch_size):\n",
        "            iou = calculate_iou(preds[j], masks[j])\n",
        "            dice = calculate_dice(preds[j], masks[j])\n",
        "            batch_iou += iou\n",
        "            batch_dice += dice\n",
        "\n",
        "        running_iou += batch_iou\n",
        "        running_dice += batch_dice\n",
        "        sample_count += batch_size\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'loss': loss.item(),\n",
        "            'iou': batch_iou / batch_size,\n",
        "            'dice': batch_dice / batch_size\n",
        "        })\n",
        "\n",
        "        # Clear some GPU memory if needed\n",
        "        del outputs, loss, preds\n",
        "        if i % 10 == 0 and torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate epoch statistics\n",
        "    epoch_loss = running_loss / sample_count\n",
        "    epoch_iou = running_iou / sample_count\n",
        "    epoch_dice = running_dice / sample_count\n",
        "\n",
        "    return epoch_loss, epoch_iou, epoch_dice\n",
        "\n",
        "# -------------------------\n",
        "# Validation Function\n",
        "# -------------------------\n",
        "def validate_enhanced(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_iou = 0.0\n",
        "    running_dice = 0.0\n",
        "    sample_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(dataloader, desc='Validation'):\n",
        "            # Move data to device\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            # Forward pass with deep supervision\n",
        "            outputs = model(images, return_deep=True)\n",
        "\n",
        "            # Calculate loss with deep supervision\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            # Get main output for metrics calculation\n",
        "            main_output = outputs[0]\n",
        "\n",
        "            # Calculate metrics\n",
        "            batch_size = images.size(0)\n",
        "            preds = torch.argmax(main_output, dim=1)\n",
        "\n",
        "            # Update statistics\n",
        "            running_loss += loss.item() * batch_size\n",
        "\n",
        "            # Calculate metrics per image\n",
        "            for j in range(batch_size):\n",
        "                iou = calculate_iou(preds[j], masks[j])\n",
        "                dice = calculate_dice(preds[j], masks[j])\n",
        "                running_iou += iou\n",
        "                running_dice += dice\n",
        "\n",
        "            sample_count += batch_size\n",
        "\n",
        "    # Calculate statistics\n",
        "    val_loss = running_loss / sample_count\n",
        "    val_iou = running_iou / sample_count\n",
        "    val_dice = running_dice / sample_count\n",
        "\n",
        "    return val_loss, val_iou, val_dice\n",
        "\n",
        "# -------------------------\n",
        "# Visualization Function\n",
        "# -------------------------\n",
        "def visualize_results(model, dataloader, device, num_samples=3):\n",
        "    model.eval()\n",
        "\n",
        "    # Get a batch of data\n",
        "    images, masks = next(iter(dataloader))\n",
        "    images = images[:num_samples].to(device)\n",
        "    masks = masks[:num_samples].to(device)\n",
        "\n",
        "    # Generate predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Denormalize images for visualization\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)\n",
        "    images = images * std + mean\n",
        "\n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Display original image\n",
        "        axes[i, 0].imshow(images[i].permute(1, 2, 0).cpu().numpy())\n",
        "        axes[i, 0].set_title(\"Original Image\")\n",
        "        axes[i, 0].axis(\"off\")\n",
        "\n",
        "        # Display ground truth mask\n",
        "        axes[i, 1].imshow(masks[i].cpu().numpy(), cmap=\"gray\")\n",
        "        axes[i, 1].set_title(\"Ground Truth\")\n",
        "        axes[i, 1].axis(\"off\")\n",
        "\n",
        "        # Display predicted mask\n",
        "        axes[i, 2].imshow(predictions[i].cpu().numpy(), cmap=\"gray\")\n",
        "        axes[i, 2].set_title(\"Prediction\")\n",
        "        axes[i, 2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"mamba_segmentation_nocbam_results.png\")\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Main Function\n",
        "# -------------------------\n",
        "def main():\n",
        "    print(\"Starting Mamba-UNet for Kvasir-SEG polyp segmentation (No CBAM, 100 Epochs)...\")\n",
        "\n",
        "    # Set the device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Set seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "\n",
        "    # Download and set up the dataset\n",
        "    kvasir_path = './datasets/kvasir-seg'\n",
        "    if not os.path.exists(os.path.join(kvasir_path, 'images')):\n",
        "        kvasir_path = download_and_setup_dataset(force_download=False)\n",
        "\n",
        "    if not kvasir_path:\n",
        "        print(\"Dataset setup failed. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Define transformations\n",
        "    transform = T.Compose([\n",
        "        T.Resize((256, 256)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    target_transform = T.Compose([\n",
        "        T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST),\n",
        "        T.ToTensor(),\n",
        "        lambda x: (x > 0.5).long()\n",
        "    ])\n",
        "\n",
        "    # Create datasets and data loaders\n",
        "    try:\n",
        "        train_dataset = KvasirSEGDataset(\n",
        "            kvasir_path,\n",
        "            split='train',\n",
        "            transform=transform,\n",
        "            target_transform=target_transform,\n",
        "            augment=True\n",
        "        )\n",
        "\n",
        "        val_dataset = KvasirSEGDataset(\n",
        "            kvasir_path,\n",
        "            split='val',\n",
        "            transform=transform,\n",
        "            target_transform=target_transform,\n",
        "            augment=False\n",
        "        )\n",
        "\n",
        "        # Use smaller batch size for more stable training\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=4,\n",
        "            shuffle=True,\n",
        "            num_workers=2,\n",
        "            pin_memory=True if torch.cuda.is_available() else False\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=4,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=True if torch.cuda.is_available() else False\n",
        "        )\n",
        "\n",
        "        print(\"Data loaders created successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating datasets: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    # Initialize enhanced model args and create model\n",
        "    args = ModelArgs()\n",
        "    model = MambaUNetSegmentationEnhanced(args).to(device)\n",
        "    print(\"Enhanced Mamba-UNet model created without CBAM attention.\")\n",
        "\n",
        "    # Define enhanced loss function and optimizer\n",
        "    criterion = DeepSupervisionLoss(main_weight=0.6, deep2_weight=0.2, deep3_weight=0.2)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "    # Add learning rate scheduler with warm restarts - adjusted for 100 epochs\n",
        "    scheduler = CosineAnnealingWarmRestarts(\n",
        "        optimizer,\n",
        "        T_0=10,  # Restart every 10 epochs\n",
        "        T_mult=2,  # Double period after each restart\n",
        "        eta_min=1e-6,\n",
        "    )\n",
        "\n",
        "    # Training loop with increased epochs\n",
        "    num_epochs = 100  # Increased to 100 as requested\n",
        "    best_iou = 0.0\n",
        "    patience_counter = 0\n",
        "    max_patience = 20  # Early stopping after 20 epochs without improvement\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_iou': [], 'train_dice': [],\n",
        "        'val_loss': [], 'val_iou': [], 'val_dice': []\n",
        "    }\n",
        "\n",
        "    print(f\"Starting training for {num_epochs} epochs...\")\n",
        "\n",
        "    try:\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            # Train with enhanced functions\n",
        "            train_loss, train_iou, train_dice = train_one_epoch_enhanced(\n",
        "                model, train_loader, optimizer, criterion, device, scheduler\n",
        "            )\n",
        "\n",
        "            # Validate\n",
        "            val_loss, val_iou, val_dice = validate_enhanced(\n",
        "                model, val_loader, criterion, device\n",
        "            )\n",
        "\n",
        "            # Save history\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['train_iou'].append(train_iou)\n",
        "            history['train_dice'].append(train_dice)\n",
        "            history['val_loss'].append(val_loss)\n",
        "            history['val_iou'].append(val_iou)\n",
        "            history['val_dice'].append(val_dice)\n",
        "\n",
        "            # Print epoch results\n",
        "            print(f\"Train - Loss: {train_loss:.4f}, IoU: {train_iou:.4f}, Dice: {train_dice:.4f}\")\n",
        "            print(f\"Val   - Loss: {val_loss:.4f}, IoU: {val_iou:.4f}, Dice: {val_dice:.4f}\")\n",
        "\n",
        "            # Save best model\n",
        "            if val_iou > best_iou:\n",
        "                best_iou = val_iou\n",
        "                torch.save(model.state_dict(), \"best_mamba_unet_nocbam_model.pth\")\n",
        "                print(f\"Model saved with IoU: {best_iou:.4f}\")\n",
        "                patience_counter = 0  # Reset patience counter\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            # Save checkpoint every 10 epochs for safety\n",
        "            if (epoch+1) % 10 == 0:\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'best_iou': best_iou,\n",
        "                    'history': history,\n",
        "                }, f\"checkpoint_nocbam_epoch_{epoch+1}.pth\")\n",
        "\n",
        "                # Plot and save training progress\n",
        "                plot_training_progress(history, epoch+1)\n",
        "\n",
        "            # Early stopping\n",
        "            if patience_counter >= max_patience:\n",
        "                print(f\"Early stopping after {max_patience} epochs without improvement\")\n",
        "                break\n",
        "\n",
        "            # Clear GPU cache between epochs\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Save checkpoint on error\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'best_iou': best_iou,\n",
        "            'history': history,\n",
        "        }, \"error_checkpoint_nocbam.pth\")\n",
        "\n",
        "    # Load best model and visualize results\n",
        "    try:\n",
        "        print(\"Loading best model for visualization...\")\n",
        "        model.load_state_dict(torch.load(\"best_mamba_unet_nocbam_model.pth\"))\n",
        "        visualize_results(model, val_loader, device)\n",
        "\n",
        "        # Plot final training history\n",
        "        plot_training_progress(history, num_epochs, final=True)\n",
        "\n",
        "        print(f\"Final best IoU: {best_iou:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during visualization: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "def plot_training_progress(history, epoch, final=False):\n",
        "    \"\"\"Plot and save training progress\"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "    plt.plot(history['val_loss'], label='Val Loss', marker='s')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss Value')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history['train_iou'], label='Train IoU', marker='o')\n",
        "    plt.plot(history['val_iou'], label='Val IoU', marker='s')\n",
        "    plt.title('IoU')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('IoU Score')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history['train_dice'], label='Train Dice', marker='o')\n",
        "    plt.plot(history['val_dice'], label='Val Dice', marker='s')\n",
        "    plt.title('Dice Coefficient')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Dice Score')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if final:\n",
        "        plt.savefig(\"mamba_unet_nocbam_final_training_history.png\")\n",
        "    else:\n",
        "        plt.savefig(f\"mamba_unet_nocbam_training_history_epoch_{epoch}.png\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMhRryqE3ZzZ",
        "outputId": "a2a258ca-94b0-4b77-cbf7-868836c539bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Mamba-UNet for Kvasir-SEG polyp segmentation (No CBAM, 100 Epochs)...\n",
            "Using device: cuda\n",
            "Downloading Kvasir-SEG dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 46.2M/46.2M [00:03<00:00, 14.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed, file saved to ./datasets/kvasir-seg.zip\n",
            "Extracting dataset...\n",
            "Extraction completed.\n",
            "Extracted file structure:\n",
            "  ./datasets/\n",
            "  ./datasets/kvasir-seg.zip\n",
            "  ./datasets/Kvasir-SEG\n",
            "  ./datasets/Kvasir-SEG/kavsir_bboxes.json\n",
            "  ./datasets/Kvasir-SEG/images\n",
            "  ./datasets/Kvasir-SEG/images/ck2395w2mb4vu07480otsu6tw.jpg\n",
            "  ./datasets/Kvasir-SEG/images/cju2qh5le1ock0878oahaql7d.jpg\n",
            "  ./datasets/Kvasir-SEG/images/cju35mdz73x890835eynq1h9v.jpg\n",
            "  ./datasets/Kvasir-SEG/images/cju2qdj95ru8g09886gfi9rsz.jpg\n",
            "  ./datasets/Kvasir-SEG/images/cju2z9vlp9j0w0801oag91sy9.jpg\n",
            "  ... and 1996 more files\n",
            "Found image directories: ['./datasets/Kvasir-SEG/images']\n",
            "Found mask directories: ['./datasets/Kvasir-SEG/masks']\n",
            "Moving images from ./datasets/Kvasir-SEG/images to ./datasets/kvasir-seg/images\n",
            "Moving masks from ./datasets/Kvasir-SEG/masks to ./datasets/kvasir-seg/masks\n",
            "Removed zip file.\n",
            "Dataset setup completed successfully.\n",
            "Found 1000 images and 1000 masks.\n",
            "Sample image names: ['cju0qkwl35piu0993l0dewei2.jpg', 'cju0qoxqj9q6s0835b43399p4.jpg', 'cju0qx73cjw570799j4n5cjze.jpg', 'cju0roawvklrq0799vmjorwfv.jpg', 'cju0rx1idathl0835detmsp84.jpg']\n",
            "Created train dataset with 800 images\n",
            "Sample image names: ['cju0qkwl35piu0993l0dewei2.jpg', 'cju0qoxqj9q6s0835b43399p4.jpg', 'cju0qx73cjw570799j4n5cjze.jpg', 'cju0roawvklrq0799vmjorwfv.jpg', 'cju0rx1idathl0835detmsp84.jpg']\n",
            "Created val dataset with 100 images\n",
            "Data loaders created successfully.\n",
            "Enhanced Mamba-UNet model created without CBAM attention.\n",
            "Starting training for 100 epochs...\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  46%|     | 93/200 [01:16<01:27,  1.23it/s, loss=0.435, iou=0.393, dice=0.559]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.0494048595428467, 1.8382571935653687]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:43<00:00,  1.22it/s, loss=0.34, iou=0.197, dice=0.247]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.4688, IoU: 0.2501, Dice: 0.3649\n",
            "Val   - Loss: 0.3817, IoU: 0.2393, Dice: 0.3314\n",
            "Model saved with IoU: 0.2393\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  97%|| 194/200 [02:36<00:04,  1.23it/s, loss=0.185, iou=0.661, dice=0.791]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.5877127647399902]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.311, iou=0.319, dice=0.468]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.3427, IoU: 0.3208, Dice: 0.4443\n",
            "Val   - Loss: 0.3661, IoU: 0.2439, Dice: 0.3422\n",
            "Model saved with IoU: 0.2439\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  22%|       | 45/200 [00:36<02:04,  1.24it/s, loss=0.296, iou=0.327, dice=0.441]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.268, iou=0.334, dice=0.451]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.3135, IoU: 0.3736, Dice: 0.5026\n",
            "Val   - Loss: 0.3236, IoU: 0.3358, Dice: 0.4537\n",
            "Model saved with IoU: 0.3358\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  26%|       | 51/200 [00:41<02:00,  1.23it/s, loss=0.209, iou=0.476, dice=0.607]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.288, iou=0.344, dice=0.438]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.3120, IoU: 0.3799, Dice: 0.5072\n",
            "Val   - Loss: 0.3224, IoU: 0.3588, Dice: 0.4807\n",
            "Model saved with IoU: 0.3588\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  12%|        | 24/200 [00:19<02:21,  1.24it/s, loss=0.335, iou=0.196, dice=0.275]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.155, iou=0.691, dice=0.812]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2958, IoU: 0.4224, Dice: 0.5501\n",
            "Val   - Loss: 0.3125, IoU: 0.3564, Dice: 0.4794\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  74%|  | 148/200 [01:59<00:41,  1.24it/s, loss=0.248, iou=0.462, dice=0.617]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6051416397094727]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.221, iou=0.418, dice=0.552]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2789, IoU: 0.4449, Dice: 0.5720\n",
            "Val   - Loss: 0.2899, IoU: 0.4029, Dice: 0.5243\n",
            "Model saved with IoU: 0.4029\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  34%|      | 69/200 [00:55<01:45,  1.24it/s, loss=0.317, iou=0.355, dice=0.504]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 1.785969614982605]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.31, iou=0.287, dice=0.406]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2846, IoU: 0.4403, Dice: 0.5663\n",
            "Val   - Loss: 0.2970, IoU: 0.3925, Dice: 0.5184\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  94%|| 187/200 [02:31<00:10,  1.24it/s, loss=0.259, iou=0.421, dice=0.524]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.236, iou=0.502, dice=0.611]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2896, IoU: 0.4288, Dice: 0.5561\n",
            "Val   - Loss: 0.3091, IoU: 0.3488, Dice: 0.4612\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  30%|       | 60/200 [00:48<01:52,  1.24it/s, loss=0.259, iou=0.419, dice=0.561]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.31, iou=0.533, dice=0.68]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2794, IoU: 0.4559, Dice: 0.5794\n",
            "Val   - Loss: 0.2775, IoU: 0.4379, Dice: 0.5599\n",
            "Model saved with IoU: 0.4379\n",
            "Epoch 10/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  94%|| 189/200 [02:32<00:08,  1.24it/s, loss=0.215, iou=0.509, dice=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.5877127647399902]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.239, iou=0.547, dice=0.633]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2618, IoU: 0.4881, Dice: 0.6130\n",
            "Val   - Loss: 0.2680, IoU: 0.4514, Dice: 0.5762\n",
            "Model saved with IoU: 0.4514\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  37%|      | 74/200 [00:59<01:41,  1.24it/s, loss=0.345, iou=0.52, dice=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.194, iou=0.572, dice=0.716]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2499, IoU: 0.5138, Dice: 0.6357\n",
            "Val   - Loss: 0.2677, IoU: 0.4509, Dice: 0.5652\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   6%|         | 11/200 [00:09<02:33,  1.23it/s, loss=0.194, iou=0.541, dice=0.678]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 1.803398847579956]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.361, iou=0.229, dice=0.334]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2393, IoU: 0.5307, Dice: 0.6534\n",
            "Val   - Loss: 0.2491, IoU: 0.4869, Dice: 0.6084\n",
            "Model saved with IoU: 0.4869\n",
            "Epoch 13/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  79%|  | 158/200 [02:07<00:33,  1.24it/s, loss=0.292, iou=0.421, dice=0.552]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-1.998030662536621, 2.4134206771850586]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.24, iou=0.466, dice=0.574]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2403, IoU: 0.5347, Dice: 0.6572\n",
            "Val   - Loss: 0.2979, IoU: 0.3771, Dice: 0.4950\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  88%| | 175/200 [02:21<00:20,  1.24it/s, loss=0.172, iou=0.585, dice=0.726]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.451, iou=0.278, dice=0.419]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2669, IoU: 0.4744, Dice: 0.5990\n",
            "Val   - Loss: 0.2758, IoU: 0.4276, Dice: 0.5484\n",
            "Epoch 15/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  12%|        | 24/200 [00:19<02:22,  1.24it/s, loss=0.329, iou=0.439, dice=0.601]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.5877127647399902]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.248, iou=0.601, dice=0.717]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2596, IoU: 0.4936, Dice: 0.6191\n",
            "Val   - Loss: 0.2707, IoU: 0.4638, Dice: 0.5895\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  54%|    | 107/200 [01:26<01:15,  1.24it/s, loss=0.233, iou=0.524, dice=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6051416397094727]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.151, iou=0.68, dice=0.806]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2486, IoU: 0.5130, Dice: 0.6396\n",
            "Val   - Loss: 0.2847, IoU: 0.4270, Dice: 0.5421\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  22%|       | 45/200 [00:36<02:04,  1.24it/s, loss=0.23, iou=0.602, dice=0.743]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-1.9295316934585571, 2.2914161682128906]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.208, iou=0.478, dice=0.583]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2356, IoU: 0.5417, Dice: 0.6608\n",
            "Val   - Loss: 0.2490, IoU: 0.4975, Dice: 0.6179\n",
            "Model saved with IoU: 0.4975\n",
            "Epoch 18/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  33%|      | 66/200 [00:53<01:48,  1.24it/s, loss=0.134, iou=0.715, dice=0.83]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.412, iou=0.549, dice=0.635]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2284, IoU: 0.5498, Dice: 0.6728\n",
            "Val   - Loss: 0.2382, IoU: 0.5187, Dice: 0.6387\n",
            "Model saved with IoU: 0.5187\n",
            "Epoch 19/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  37%|      | 74/200 [00:59<01:41,  1.24it/s, loss=0.17, iou=0.531, dice=0.679]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.158, iou=0.759, dice=0.849]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2221, IoU: 0.5601, Dice: 0.6811\n",
            "Val   - Loss: 0.2276, IoU: 0.5400, Dice: 0.6667\n",
            "Model saved with IoU: 0.5400\n",
            "Epoch 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  40%|      | 80/200 [01:04<01:36,  1.24it/s, loss=0.169, iou=0.628, dice=0.744]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-1.8439079523086548, 2.2216994762420654]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.279, iou=0.413, dice=0.497]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2106, IoU: 0.5893, Dice: 0.7049\n",
            "Val   - Loss: 0.2243, IoU: 0.5383, Dice: 0.6517\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  24%|       | 48/200 [00:38<02:02,  1.24it/s, loss=0.227, iou=0.463, dice=0.611]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.061, iou=0.878, dice=0.932]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2059, IoU: 0.5999, Dice: 0.7174\n",
            "Val   - Loss: 0.2226, IoU: 0.5435, Dice: 0.6517\n",
            "Model saved with IoU: 0.5435\n",
            "Epoch 22/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  83%| | 166/200 [02:14<00:27,  1.24it/s, loss=0.17, iou=0.782, dice=0.871]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.015155553817749, 2.2914161682128906]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.178, iou=0.568, dice=0.704]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2009, IoU: 0.6111, Dice: 0.7235\n",
            "Val   - Loss: 0.2110, IoU: 0.5729, Dice: 0.6905\n",
            "Model saved with IoU: 0.5729\n",
            "Epoch 23/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  30%|       | 60/200 [00:48<01:52,  1.24it/s, loss=0.123, iou=0.668, dice=0.787]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.328, iou=0.544, dice=0.659]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1902, IoU: 0.6263, Dice: 0.7379\n",
            "Val   - Loss: 0.2064, IoU: 0.5799, Dice: 0.6922\n",
            "Model saved with IoU: 0.5799\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  32%|      | 65/200 [00:52<01:49,  1.24it/s, loss=0.274, iou=0.608, dice=0.726]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.032280206680298, 2.1519827842712402]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.0717, iou=0.839, dice=0.912]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1846, IoU: 0.6372, Dice: 0.7481\n",
            "Val   - Loss: 0.2111, IoU: 0.5743, Dice: 0.6838\n",
            "Epoch 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|      | 75/200 [01:00<01:40,  1.24it/s, loss=0.124, iou=0.749, dice=0.856]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.395991325378418]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.14, iou=0.619, dice=0.755]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1859, IoU: 0.6392, Dice: 0.7488\n",
            "Val   - Loss: 0.2049, IoU: 0.5911, Dice: 0.7044\n",
            "Model saved with IoU: 0.5911\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  71%|   | 142/200 [01:54<00:47,  1.23it/s, loss=0.185, iou=0.627, dice=0.69]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.142, iou=0.745, dice=0.851]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2042, IoU: 0.6087, Dice: 0.7224\n",
            "Val   - Loss: 0.2638, IoU: 0.5070, Dice: 0.6329\n",
            "Epoch 27/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  19%|        | 38/200 [00:31<02:10,  1.24it/s, loss=0.171, iou=0.646, dice=0.764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.0836544036865234, 2.5354249477386475]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.29, iou=0.566, dice=0.709]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2146, IoU: 0.5800, Dice: 0.6993\n",
            "Val   - Loss: 0.2337, IoU: 0.5316, Dice: 0.6475\n",
            "Epoch 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  66%|   | 132/200 [01:46<00:55,  1.23it/s, loss=0.21, iou=0.647, dice=0.772]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.208, iou=0.721, dice=0.81]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2085, IoU: 0.5985, Dice: 0.7141\n",
            "Val   - Loss: 0.2240, IoU: 0.5433, Dice: 0.6606\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  97%|| 194/200 [02:36<00:04,  1.24it/s, loss=0.16, iou=0.601, dice=0.675]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.226, iou=0.544, dice=0.695]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2101, IoU: 0.5905, Dice: 0.7054\n",
            "Val   - Loss: 0.2095, IoU: 0.5607, Dice: 0.6775\n",
            "Epoch 30/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  36%|      | 72/200 [00:58<01:44,  1.23it/s, loss=0.089, iou=0.788, dice=0.876]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.2914161682128906]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.254, iou=0.335, dice=0.403]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2040, IoU: 0.6062, Dice: 0.7200\n",
            "Val   - Loss: 0.2121, IoU: 0.5806, Dice: 0.6929\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  33%|      | 66/200 [00:53<01:47,  1.24it/s, loss=0.163, iou=0.596, dice=0.728]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.313, iou=0.352, dice=0.441]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.2044, IoU: 0.6054, Dice: 0.7197\n",
            "Val   - Loss: 0.2434, IoU: 0.5136, Dice: 0.6204\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  58%|    | 117/200 [01:34<01:06,  1.24it/s, loss=0.113, iou=0.624, dice=0.695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpgImage shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6051416397094727]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.203, iou=0.553, dice=0.658]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1958, IoU: 0.6187, Dice: 0.7304\n",
            "Val   - Loss: 0.2277, IoU: 0.5604, Dice: 0.6800\n",
            "Epoch 33/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  19%|        | 38/200 [00:30<02:11,  1.24it/s, loss=0.338, iou=0.41, dice=0.565]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-1.9466564655303955, 1.6639653444290161]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.173, iou=0.61, dice=0.749]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1914, IoU: 0.6285, Dice: 0.7397\n",
            "Val   - Loss: 0.2019, IoU: 0.5917, Dice: 0.7013\n",
            "Model saved with IoU: 0.5917\n",
            "Epoch 34/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  90%| | 181/200 [02:26<00:15,  1.23it/s, loss=0.229, iou=0.487, dice=0.635]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-1.878157377243042, 2.273987293243408]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.297, iou=0.509, dice=0.626]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1903, IoU: 0.6353, Dice: 0.7448\n",
            "Val   - Loss: 0.2005, IoU: 0.6117, Dice: 0.7254\n",
            "Model saved with IoU: 0.6117\n",
            "Epoch 35/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  34%|      | 68/200 [00:55<01:46,  1.24it/s, loss=0.151, iou=0.658, dice=0.758]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.5877127647399902]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.114, iou=0.742, dice=0.843]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1799, IoU: 0.6440, Dice: 0.7530\n",
            "Val   - Loss: 0.2176, IoU: 0.5909, Dice: 0.7041\n",
            "Epoch 36/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  29%|       | 58/200 [00:47<01:54,  1.24it/s, loss=0.131, iou=0.75, dice=0.834]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.235, iou=0.509, dice=0.668]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1773, IoU: 0.6527, Dice: 0.7596\n",
            "Val   - Loss: 0.2037, IoU: 0.5936, Dice: 0.7076\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|      | 77/200 [01:02<01:38,  1.24it/s, loss=0.4, iou=0.578, dice=0.692]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.132, iou=0.738, dice=0.826]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1723, IoU: 0.6623, Dice: 0.7659\n",
            "Val   - Loss: 0.1996, IoU: 0.6029, Dice: 0.7169\n",
            "Epoch 38/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|      | 75/200 [01:00<01:41,  1.23it/s, loss=0.223, iou=0.539, dice=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.123, iou=0.707, dice=0.789]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1646, IoU: 0.6785, Dice: 0.7814\n",
            "Val   - Loss: 0.1871, IoU: 0.6299, Dice: 0.7307\n",
            "Model saved with IoU: 0.6299\n",
            "Epoch 39/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  14%|        | 27/200 [00:21<02:19,  1.24it/s, loss=0.0852, iou=0.801, dice=0.885]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.0836544036865234, 2.1519827842712402]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.375, iou=0.516, dice=0.655]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1612, IoU: 0.6864, Dice: 0.7869\n",
            "Val   - Loss: 0.1790, IoU: 0.6490, Dice: 0.7550\n",
            "Model saved with IoU: 0.6490\n",
            "Epoch 40/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  20%|        | 39/200 [00:31<02:09,  1.24it/s, loss=0.0793, iou=0.798, dice=0.881]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.112, iou=0.802, dice=0.876]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1533, IoU: 0.6970, Dice: 0.7949\n",
            "Val   - Loss: 0.1894, IoU: 0.6192, Dice: 0.7256\n",
            "Epoch 41/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  22%|       | 43/200 [00:35<02:07,  1.23it/s, loss=0.0477, iou=0.88, dice=0.934]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.5877127647399902]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.23it/s, loss=0.207, iou=0.478, dice=0.607]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1540, IoU: 0.6981, Dice: 0.7957\n",
            "Val   - Loss: 0.1757, IoU: 0.6455, Dice: 0.7479\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  84%| | 169/200 [02:16<00:25,  1.24it/s, loss=0.158, iou=0.569, dice=0.639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.465708017349243]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.0937, iou=0.751, dice=0.855]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1447, IoU: 0.7158, Dice: 0.8109\n",
            "Val   - Loss: 0.1738, IoU: 0.6619, Dice: 0.7573\n",
            "Model saved with IoU: 0.6619\n",
            "Epoch 43/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  74%|  | 148/200 [01:59<00:41,  1.24it/s, loss=0.115, iou=0.66, dice=0.773]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpgImage shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-1.878157377243042, 1.785969614982605]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.0607, iou=0.873, dice=0.931]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1467, IoU: 0.7147, Dice: 0.8087\n",
            "Val   - Loss: 0.1668, IoU: 0.6758, Dice: 0.7728\n",
            "Model saved with IoU: 0.6758\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  48%|     | 96/200 [01:17<01:24,  1.24it/s, loss=0.174, iou=0.689, dice=0.802]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1007792949676514, 2.3785624504089355]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.132, iou=0.665, dice=0.779]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1438, IoU: 0.7157, Dice: 0.8097\n",
            "Val   - Loss: 0.1738, IoU: 0.6569, Dice: 0.7530\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   2%|         | 4/200 [00:03<02:43,  1.20it/s, loss=0.154, iou=0.674, dice=0.796]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.5877127647399902]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.0626, iou=0.841, dice=0.908]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1372, IoU: 0.7283, Dice: 0.8211\n",
            "Val   - Loss: 0.1712, IoU: 0.6747, Dice: 0.7643\n",
            "Epoch 46/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  32%|      | 65/200 [00:52<01:49,  1.24it/s, loss=0.114, iou=0.696, dice=0.781]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.167, iou=0.574, dice=0.656]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1390, IoU: 0.7256, Dice: 0.8165\n",
            "Val   - Loss: 0.1646, IoU: 0.6844, Dice: 0.7754\n",
            "Model saved with IoU: 0.6844\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  58%|    | 116/200 [01:34<01:07,  1.24it/s, loss=0.222, iou=0.611, dice=0.727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6051416397094727]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.23it/s, loss=0.0955, iou=0.79, dice=0.879]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1324, IoU: 0.7368, Dice: 0.8269\n",
            "Val   - Loss: 0.1630, IoU: 0.6868, Dice: 0.7786\n",
            "Model saved with IoU: 0.6868\n",
            "Epoch 48/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  56%|    | 113/200 [01:31<01:10,  1.23it/s, loss=0.152, iou=0.659, dice=0.78]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-1.878157377243042, 1.5593901872634888]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:42<00:00,  1.23it/s, loss=0.0757, iou=0.775, dice=0.862]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1303, IoU: 0.7397, Dice: 0.8287\n",
            "Val   - Loss: 0.1720, IoU: 0.6746, Dice: 0.7646\n",
            "Epoch 49/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  70%|   | 140/200 [01:53<00:48,  1.24it/s, loss=0.114, iou=0.769, dice=0.865]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.111, iou=0.791, dice=0.882]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1282, IoU: 0.7405, Dice: 0.8295\n",
            "Val   - Loss: 0.1633, IoU: 0.6847, Dice: 0.7771\n",
            "Epoch 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  64%|   | 129/200 [01:44<00:57,  1.24it/s, loss=0.123, iou=0.755, dice=0.858]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.169, iou=0.696, dice=0.764]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1277, IoU: 0.7465, Dice: 0.8349\n",
            "Val   - Loss: 0.1642, IoU: 0.6854, Dice: 0.7757\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  60%|    | 121/200 [01:38<01:04,  1.23it/s, loss=0.103, iou=0.714, dice=0.833]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.082265853881836]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.126, iou=0.869, dice=0.924]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1240, IoU: 0.7493, Dice: 0.8378\n",
            "Val   - Loss: 0.1663, IoU: 0.6823, Dice: 0.7731\n",
            "Epoch 52/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|      | 76/200 [01:01<01:39,  1.24it/s, loss=0.0486, iou=0.895, dice=0.944]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5ekty5ckzf07550c9u3ckk.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.6225709915161133]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|| 200/200 [02:41<00:00,  1.24it/s, loss=0.493, iou=0.326, dice=0.459]\n",
            "Validation:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image path: ./datasets/kvasir-seg/images/cju5knbbqfipk080128cggukq.jpg\n",
            "Mask path: ./datasets/kvasir-seg/masks/cju5knbbqfipk080128cggukq.jpg\n",
            "Image shape: torch.Size([3, 256, 256]), dtype: torch.float32, range: [-2.1179039478302, 2.640000104904175]\n",
            "Mask shape: torch.Size([1, 256, 256]), dtype: torch.int64, range: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|| 25/25 [00:05<00:00,  4.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.1563, IoU: 0.6900, Dice: 0.7903\n",
            "Val   - Loss: 0.2039, IoU: 0.6065, Dice: 0.7094\n",
            "Epoch 53/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch - Images: torch.Size([4, 3, 256, 256]), Masks: torch.Size([4, 256, 256])\n",
            "Masks unique values: tensor([0, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  12%|        | 25/200 [00:20<02:21,  1.24it/s, loss=0.108, iou=0.742, dice=0.837]"
          ]
        }
      ]
    }
  ]
}