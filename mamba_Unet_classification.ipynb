{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxPA37mVp4HJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "import torchvision.transforms as T\n",
        "from einops import rearrange, repeat\n",
        "import math\n",
        "import os\n",
        "\n",
        "# -------------------------\n",
        "# Selective Scan\n",
        "# -------------------------\n",
        "def selective_scan(u, delta, A, B, C, D):\n",
        "    dA = torch.einsum('bld,dn->bldn', delta, A)\n",
        "    dB_u = torch.einsum('bld,bld,bln->bldn', delta, u, B)\n",
        "\n",
        "    dA_cumsum = torch.cat([dA[:, 1:], torch.zeros_like(dA[:, :1])], dim=1)\n",
        "    dA_cumsum = torch.flip(dA_cumsum, dims=[1])\n",
        "    dA_cumsum = torch.cumsum(dA_cumsum, dim=1)\n",
        "    dA_cumsum = torch.exp(dA_cumsum)\n",
        "    dA_cumsum = torch.flip(dA_cumsum, dims=[1])\n",
        "\n",
        "    x = dB_u * dA_cumsum\n",
        "    x = torch.cumsum(x, dim=1) / (dA_cumsum + 1e-12)\n",
        "\n",
        "    y = torch.einsum('bldn,bln->bld', x, C)\n",
        "    return y + u * D\n",
        "\n",
        "# -------------------------\n",
        "# Model Args\n",
        "# -------------------------\n",
        "class ModelArgs:\n",
        "    def __init__(self):\n",
        "        self.model_input_dims = 32\n",
        "        self.model_states = 32\n",
        "        self.projection_expand_factor = 2\n",
        "        self.conv_kernel_size = 4\n",
        "        self.conv_use_bias = True\n",
        "        self.dense_use_bias = False\n",
        "        self.layer_id = -1\n",
        "        self.seq_length = 128\n",
        "        self.num_layers = 5\n",
        "        self.dropout_rate = 0.2\n",
        "        self.use_lm_head = False\n",
        "        self.num_classes = 37\n",
        "        self.final_activation = 'softmax'\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam\n",
        "        self.metrics = ['accuracy']\n",
        "        self.model_internal_dim = self.projection_expand_factor * self.model_input_dims\n",
        "        self.delta_t_rank = math.ceil(self.model_input_dims / 16)\n",
        "\n",
        "# -------------------------\n",
        "# Mamba + Residual Blocks\n",
        "# -------------------------\n",
        "class MambaBlock(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.in_proj = nn.Linear(args.model_input_dims, args.model_internal_dim * 2, bias=False)\n",
        "        self.conv1d = nn.Conv1d(args.model_internal_dim, args.model_internal_dim, kernel_size=args.conv_kernel_size,\n",
        "                                padding=args.conv_kernel_size-1, groups=args.model_internal_dim)\n",
        "        self.x_proj = nn.Linear(args.model_internal_dim, args.delta_t_rank + args.model_states * 2, bias=False)\n",
        "        self.delta_proj = nn.Linear(args.delta_t_rank, args.model_internal_dim)\n",
        "\n",
        "        A_vals = torch.arange(1, args.model_states + 1).float()\n",
        "        self.A_log = nn.Parameter(torch.log(repeat(A_vals, 'n -> d n', d=args.model_internal_dim)))\n",
        "        self.D = nn.Parameter(torch.ones(args.model_internal_dim))\n",
        "        self.out_proj = nn.Linear(args.model_internal_dim, args.model_input_dims, bias=args.dense_use_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, l, d = x.shape\n",
        "        x_and_res = self.in_proj(x)\n",
        "        x1, res = x_and_res.chunk(2, dim=-1)\n",
        "\n",
        "        x1 = rearrange(x1, 'b l d -> b d l')\n",
        "        x1 = self.conv1d(x1)[..., :l]\n",
        "        x1 = rearrange(x1, 'b d l -> b l d')\n",
        "        x1 = F.silu(x1)\n",
        "\n",
        "        A = -torch.exp(self.A_log)\n",
        "        D = self.D\n",
        "        x_dbl = self.x_proj(x1)\n",
        "        delta, B, C = torch.split(x_dbl, [self.args.delta_t_rank, self.args.model_states, self.args.model_states], dim=-1)\n",
        "        delta = F.softplus(self.delta_proj(delta))\n",
        "\n",
        "        y = selective_scan(x1, delta, A, B, C, D)\n",
        "        y = y * F.silu(res)\n",
        "        return self.out_proj(y)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(args.model_input_dims)\n",
        "        self.mixer = MambaBlock(args)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mixer(self.norm(x)) + x\n",
        "\n",
        "# -------------------------\n",
        "# Mamba-UNet Architecture\n",
        "# -------------------------\n",
        "class MambaUNet(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(*[ResidualBlock(args) for _ in range(args.num_layers)])\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Conv2d(32, args.num_classes, kernel_size=1)\n",
        "        )\n",
        "        self.activation = nn.Softmax(dim=1) if args.final_activation == 'softmax' else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        b, c, h, w = x.size()\n",
        "        x = x.permute(0, 2, 3, 1).reshape(b, h * w, c)\n",
        "        x = self.res_blocks(x)\n",
        "        x = x.reshape(b, h, w, c).permute(0, 3, 1, 2)\n",
        "        x = self.decoder(x)\n",
        "        return self.activation(x)\n",
        "\n",
        "# -------------------------\n",
        "# Dataset and Training\n",
        "# -------------------------\n",
        "def get_dataloaders(batch_size=4):\n",
        "    transform = T.Compose([\n",
        "        T.Resize((128, 128)),\n",
        "        T.ToTensor()\n",
        "    ])\n",
        "\n",
        "    train_ds = OxfordIIITPet(root='.', split='trainval', download=True, target_types='category', transform=transform)\n",
        "    test_ds = OxfordIIITPet(root='.', split='test', download=True, target_types='category', transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    pbar = tqdm(train_loader, desc='Training', leave=False)\n",
        "    for imgs, labels in pbar:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        outputs = outputs.mean(dim=(2, 3))  # global average pooling\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        pred = outputs.argmax(dim=1)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        total += imgs.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=total_loss/total, acc=correct/total)\n",
        "    print(f\"Train Loss: {total_loss/total:.4f} | Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            outputs = outputs.mean(dim=(2, 3))\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            pred = outputs.argmax(dim=1)\n",
        "            correct += (pred == labels).sum().item()\n",
        "            total += imgs.size(0)\n",
        "\n",
        "    print(f\"Test Loss: {total_loss/total:.4f} | Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# Main\n",
        "# -------------------------\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    args = ModelArgs()\n",
        "    model = MambaUNet(args).to(device)\n",
        "    train_loader, test_loader = get_dataloaders()\n",
        "    optimizer = args.optimizer(model.parameters(), lr=1e-3)\n",
        "    criterion = args.loss\n",
        "\n",
        "    for epoch in range(1, 11):\n",
        "        print(f\"\\nEpoch {epoch}\")\n",
        "        train(model, train_loader, optimizer, criterion, device)\n",
        "        test(model, test_loader, criterion, device)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gsNJHLrp54j",
        "outputId": "5a70f8ce-7c6f-43b7-c734-e4107e443872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 13/920 [08:21<9:48:11, 38.91s/it, acc=0.0385, loss=3.61]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################# train on MINST\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as T\n",
        "from einops import rearrange, repeat\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------------------------\n",
        "# Selective Scan\n",
        "# -------------------------\n",
        "def selective_scan(u, delta, A, B, C, D):\n",
        "    dA = torch.einsum('bld,dn->bldn', delta, A)\n",
        "    dB_u = torch.einsum('bld,bld,bln->bldn', delta, u, B)\n",
        "\n",
        "    dA_cumsum = torch.cat([dA[:, 1:], torch.zeros_like(dA[:, :1])], dim=1)\n",
        "    dA_cumsum = torch.flip(dA_cumsum, dims=[1])\n",
        "    dA_cumsum = torch.cumsum(dA_cumsum, dim=1)\n",
        "    dA_cumsum = torch.exp(dA_cumsum)\n",
        "    dA_cumsum = torch.flip(dA_cumsum, dims=[1])\n",
        "\n",
        "    x = dB_u * dA_cumsum\n",
        "    x = torch.cumsum(x, dim=1) / (dA_cumsum + 1e-12)\n",
        "\n",
        "    y = torch.einsum('bldn,bln->bld', x, C)\n",
        "    return y + u * D\n",
        "\n",
        "# -------------------------\n",
        "# Model Args\n",
        "# -------------------------\n",
        "class ModelArgs:\n",
        "    def __init__(self):\n",
        "        self.model_input_dims = 16\n",
        "        self.model_states = 16\n",
        "        self.projection_expand_factor = 1\n",
        "        self.conv_kernel_size = 4\n",
        "        self.conv_use_bias = True\n",
        "        self.dense_use_bias = False\n",
        "        self.layer_id = -1\n",
        "        self.seq_length = 128\n",
        "        self.num_layers = 3\n",
        "        self.dropout_rate = 0.2\n",
        "        self.use_lm_head = False\n",
        "        self.num_classes = 10  # MNIST has 10 classes\n",
        "        self.final_activation = 'softmax'\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam\n",
        "        self.metrics = ['accuracy']\n",
        "        self.model_internal_dim = self.projection_expand_factor * self.model_input_dims\n",
        "        self.delta_t_rank = math.ceil(self.model_input_dims / 16)\n",
        "\n",
        "# -------------------------\n",
        "# Mamba + Residual Blocks\n",
        "# -------------------------\n",
        "class MambaBlock(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.in_proj = nn.Linear(args.model_input_dims, args.model_internal_dim * 2, bias=False)\n",
        "        self.conv1d = nn.Conv1d(args.model_internal_dim, args.model_internal_dim, kernel_size=args.conv_kernel_size,\n",
        "                                padding=args.conv_kernel_size - 1, groups=args.model_internal_dim)\n",
        "        self.x_proj = nn.Linear(args.model_internal_dim, args.delta_t_rank + args.model_states * 2, bias=False)\n",
        "        self.delta_proj = nn.Linear(args.delta_t_rank, args.model_internal_dim)\n",
        "\n",
        "        A_vals = torch.arange(1, args.model_states + 1).float()\n",
        "        self.A_log = nn.Parameter(torch.log(repeat(A_vals, 'n -> d n', d=args.model_internal_dim)))\n",
        "        self.D = nn.Parameter(torch.ones(args.model_internal_dim))\n",
        "        self.out_proj = nn.Linear(args.model_internal_dim, args.model_input_dims, bias=args.dense_use_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, l, d = x.shape\n",
        "        x_and_res = self.in_proj(x)\n",
        "        x1, res = x_and_res.chunk(2, dim=-1)\n",
        "\n",
        "        x1 = rearrange(x1, 'b l d -> b d l')\n",
        "        x1 = self.conv1d(x1)[..., :l]\n",
        "        x1 = rearrange(x1, 'b d l -> b l d')\n",
        "        x1 = F.selu(x1)\n",
        "\n",
        "        A = -torch.exp(self.A_log)\n",
        "        D = self.D\n",
        "        x_dbl = self.x_proj(x1)\n",
        "        delta, B, C = torch.split(x_dbl, [self.args.delta_t_rank, self.args.model_states, self.args.model_states], dim=-1)\n",
        "        delta = F.softplus(self.delta_proj(delta))\n",
        "\n",
        "        y = selective_scan(x1, delta, A, B, C, D)\n",
        "        y = y * F.selu(res)\n",
        "        return self.out_proj(y)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(args.model_input_dims)\n",
        "        self.mixer = MambaBlock(args)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mixer(self.norm(x)) + x\n",
        "\n",
        "# -------------------------\n",
        "# Mamba-UNet Architecture\n",
        "# -------------------------\n",
        "class MambaUNet(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # Changed for MNIST (1 channel)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(*[ResidualBlock(args) for _ in range(args.num_layers)])\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Conv2d(16, args.num_classes, kernel_size=1)\n",
        "        )\n",
        "        self.activation = nn.Softmax(dim=1) if args.final_activation == 'softmax' else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        b, c, h, w = x.size()\n",
        "        x = x.permute(0, 2, 3, 1).reshape(b, h * w, c)\n",
        "        x = self.res_blocks(x)\n",
        "        x = x.reshape(b, h, w, c).permute(0, 3, 1, 2)\n",
        "        x = self.decoder(x)\n",
        "        return self.activation(x)\n",
        "\n",
        "# -------------------------\n",
        "# Dataset and Training\n",
        "# -------------------------\n",
        "def get_dataloaders(batch_size=4):\n",
        "    transform = T.Compose([\n",
        "        T.Resize((128, 128)),\n",
        "        T.ToTensor()\n",
        "    ])\n",
        "\n",
        "    train_ds = MNIST(root='.', train=True, download=True, transform=transform)\n",
        "    test_ds = MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    pbar = tqdm(train_loader, desc='Training', leave=False)\n",
        "    for imgs, labels in pbar:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        outputs = outputs.mean(dim=(2, 3))  # global average pooling\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        pred = outputs.argmax(dim=1)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        total += imgs.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=total_loss/total, acc=correct/total)\n",
        "    print(f\"Train Loss: {total_loss/total:.4f} | Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            outputs = outputs.mean(dim=(2, 3))\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            pred = outputs.argmax(dim=1)\n",
        "            correct += (pred == labels).sum().item()\n",
        "            total += imgs.size(0)\n",
        "\n",
        "    print(f\"Test Loss: {total_loss/total:.4f} | Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# Main\n",
        "# -------------------------\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    args = ModelArgs()\n",
        "    model = MambaUNet(args).to(device)\n",
        "    train_loader, test_loader = get_dataloaders()\n",
        "    optimizer = args.optimizer(model.parameters(), lr=1e-3)\n",
        "    criterion = args.loss\n",
        "\n",
        "    for epoch in range(1, 11):\n",
        "        print(f\"\\nEpoch {epoch}\")\n",
        "        train(model, train_loader, optimizer, criterion, device)\n",
        "        test(model, test_loader, criterion, device)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht7NRxLm_QOI",
        "outputId": "b8213b1d-d7f7-4f0b-8440-b0b7179d6f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 48.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.68MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.4MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.42MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.1847 | Accuracy: 0.2871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.1222 | Accuracy: 0.3273\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.1178 | Accuracy: 0.3677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.0527 | Accuracy: 0.4238\n",
            "\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.0425 | Accuracy: 0.4334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.0069 | Accuracy: 0.4789\n",
            "\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.0227 | Accuracy: 0.4754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.0401 | Accuracy: 0.4685\n",
            "\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.9904 | Accuracy: 0.5237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.1937 | Accuracy: 0.2636\n",
            "\n",
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.1124 | Accuracy: 0.3619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.9976 | Accuracy: 0.4987\n",
            "\n",
            "Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.0995 | Accuracy: 0.3712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.2262 | Accuracy: 0.2158\n",
            "\n",
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.2646 | Accuracy: 0.1811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.3346 | Accuracy: 0.1010\n",
            "\n",
            "Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.2637 | Accuracy: 0.1883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.3131 | Accuracy: 0.1259\n",
            "\n",
            "Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   6%|▌         | 925/15000 [00:40<10:03, 23.32it/s, acc=0.124, loss=2.3]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchview graphviz\n",
        "!apt install graphviz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzdgmaHQ5vGN",
        "outputId": "75ca0182-a3eb-4cdd-e1b2-82c20296f001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchview\n",
            "  Downloading torchview-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.20.3)\n",
            "Downloading torchview-0.2.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: torchview\n",
            "Successfully installed torchview-0.2.7\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchview import draw_graph\n",
        "# # Ensure your model code is in model.py or adjust the import\n",
        "\n",
        "# Initialize model and args\n",
        "args = ModelArgs()\n",
        "model = MambaUNet(args)\n",
        "\n",
        "# Dummy input: RGB image of size 128x128\n",
        "dummy_input = torch.randn(1, 3, 128, 128)\n",
        "\n",
        "# Create the graph\n",
        "graph = draw_graph(\n",
        "    model,\n",
        "    input_data=dummy_input,\n",
        "    expand_nested=True,\n",
        "    graph_dir='TB',  # Top-to-bottom layout\n",
        "    roll=True\n",
        ")\n",
        "\n",
        "# Render and save as PDF\n",
        "graph.visual_graph.render(\n",
        "    filename=\"mamba_unet_diagram\",\n",
        "    directory=\"./\",\n",
        "    format=\"pdf\",\n",
        "    cleanup=True\n",
        ")\n",
        "\n",
        "print(\"PDF saved as mamba_unet_diagram.pdf\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OwjUSAG5CVO",
        "outputId": "3f02c8b5-8497-4218-ccb8-e4f9382ff011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF saved as mamba_unet_diagram.pdf\n"
          ]
        }
      ]
    }
  ]
}